# ğŸ“˜ Vietnamese TTS Training Guide (Pre-computed Flow)

HÆ°á»›ng dáº«n training model Chatterbox TTS cho tiáº¿ng Viá»‡t sá»­ dá»¥ng luá»“ng **Pre-computed** (Tá»‘i Æ°u cho Production).

## ğŸš€ Workflow

```mermaid
graph LR
    A[Metadata CSV] --> B[preprocess_dataset.py]
    B --> C[Dataset Ä‘Ã£ xá»­ lÃ½ (.pt files)]
    C --> D[train/run.py]
    D --> E[Checkpoints]
```

---

## 1. CÃ i Ä‘áº·t

CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t cho training:

```bash
pip install -r requirements.txt
pip install -r viterbox-tts/requirements-train.txt
```

---

## 2. Chuáº©n bá»‹ Dá»¯ liá»‡u

Táº¡o file `metadata.csv` vá»›i Ä‘á»‹nh dáº¡ng: `audio_path|transcript`.

**VÃ­ dá»¥ `metadata.csv`:**
```csv
audio|transcript
wavs/audio_001.wav|Xin chÃ o cÃ¡c báº¡n.
wavs/audio_002.wav|HÃ´m nay trá»i Ä‘áº¹p quÃ¡.
/absolute/path/valid.wav|ÄÆ°á»ng dáº«n tuyá»‡t Ä‘á»‘i cÅ©ng Ä‘Æ°á»£c há»— trá»£.
```

> **LÆ°u Ã½:**
> - Audio nÃªn lÃ  file WAV (mono). Sample rate sáº½ tá»± Ä‘á»™ng Ä‘Æ°á»£c convert vá» 16kHz.
> - Transcript nÃªn lÃ  tiáº¿ng Viá»‡t cÃ³ dáº¥u.

---

## 3. BÆ°á»›c 1: Pre-processing (Xá»­ lÃ½ dá»¯ liá»‡u)

Cháº¡y script nÃ y Ä‘á»ƒ tÃ­nh toÃ¡n trÆ°á»›c embeddings vÃ  tokens. BÆ°á»›c nÃ y giÃºp training nhanh hÆ¡n 5-10 láº§n.

**Cháº¡y vá»›i GPU (KhuyÃªn dÃ¹ng - Nhanh nháº¥t vá»›i batching):**
```bash
python preprocess_dataset.py \
    --metadata_csv metadata.csv \
    --audio_dir wavs \
    --output_dir ./preprocessed \
    --checkpoint ./vietnamese/pretrained_model_download \
    --device cuda \
    --batch_size 16 \
    --num_workers 1
```

**Tham sá»‘ quan trá»ng:**
- `--metadata_csv`: ÄÆ°á»ng dáº«n file metadata.
- `--audio_dir`: ThÆ° má»¥c chá»©a file audio.
- `--output_dir`: ThÆ° má»¥c lÆ°u file `.pt` Ä‘Ã£ xá»­ lÃ½.
- `--batch_size`: Batch size cho GPU (default: 1, recommended: 8-16 cho GPU).
- `--num_workers`: Sá»‘ luá»“ng xá»­ lÃ½ (DÃ¹ng 1 cho GPU Ä‘á»ƒ trÃ¡nh OOM, dÃ¹ng 4-8 cho CPU).

---

## 4. BÆ°á»›c 2: Training

Sá»­ dá»¥ng `train/run.py` Ä‘á»ƒ training tá»« dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½.

> **LÆ°u Ã½**: Script training náº±m á»Ÿ `train/run.py` (khÃ´ng pháº£i `train_precomputed.py`)

### CÃ¡ch 1: Fine-tuning tiÃªu chuáº©n (Full Model)

DÃ nh cho dataset lá»›n (>10h) hoáº·c khi cáº§n cháº¥t lÆ°á»£ng cao nháº¥t.

```bash
python train/run.py \
    --preprocessed_dir ./preprocessed \
    --output_dir ./checkpoints/vietnamese_full \
    --epochs 20 \
    --batch_size 8 \
    --lr 5e-5 \
    --use_wandb
```

### CÃ¡ch 2: LoRA Fine-tuning (KhuyÃªn dÃ¹ng cho 2-5h audio) â­ UPDATED

**Tá»‘i Æ°u má»›i (Tier 1)**: TÄƒng capacity vÃ  focus vÃ o voice quality!

```bash
python train/run.py \
    --preprocessed_dir ./preprocessed \
    --output_dir ./checkpoints/vietnamese_lora \
    --epochs 20 \
    --batch_size 8 \
    --lr 5e-4 \
    --use_lora \
    --lora_r 32 \
    --lora_alpha 64 \
    --text_weight 0.05 \
    --speech_weight 2.0 \
    --use_wandb
```

**Thay Ä‘á»•i quan trá»ng**:
- âœ… `lora_r=32` (tÄƒng tá»« 8): Nhiá»u capacity hÆ¡n 4x Ä‘á»ƒ há»c voice patterns
- âœ… `lora_alpha=64` (tÄƒng tá»« 16): Tá»· lá»‡ scaling tÆ°Æ¡ng á»©ng
- âœ… Target modules: Bao gá»“m cáº£ MLP layers (gate_proj, up_proj, down_proj)
- âœ… `text_weight=0.05`: Giáº£m focus vÃ o text (há»c nhanh)  
- âœ… `speech_weight=2.0`: TÄƒng focus vÃ o voice quality
- âœ… `lr=5e-4`: Learning rate cao hÆ¡n cho LoRA (tá»« 1e-4)
- âœ… `epochs=20`: Train lÃ¢u hÆ¡n Ä‘á»ƒ há»c tá»‘t voice

**Káº¿t quáº£ mong Ä‘á»£i**: Voice adaptation tá»« 3/10 â†’ 7-9/10

**CÃ¡c tÃ­nh nÄƒng nÃ¢ng cao Ä‘Ã£ báº­t máº·c Ä‘á»‹nh:**
- âœ… **Safe Z-Loss**: á»”n Ä‘á»‹nh training, trÃ¡nh NaN.
- âœ… **Dynamic Batching**: Gom nhÃ³m audio cÃ¹ng Ä‘á»™ dÃ i -> Train nhanh hÆ¡n.
- âœ… **Gradient Checkpointing**: Tiáº¿t kiá»‡m 30% VRAM.
- âœ… **Best Model Saving**: Tá»± Ä‘á»™ng lÆ°u model tá»‘t nháº¥t theo loss giá»ng nÃ³i.

---

## 5. Monitoring (WandB)

Script há»— trá»£ Weights & Biases Ä‘á»ƒ theo dÃµi biá»ƒu Ä‘á»“ loss trá»±c quan.

ThÃªm `--use_wandb` vÃ o lá»‡nh training.
- Project máº·c Ä‘á»‹nh: `vietnamese-tts`
- Biá»ƒu Ä‘á»“ quan trá»ng cáº§n theo dÃµi:
  - `loss/loss_speech`: Loss pháº§n sinh giá»ng nÃ³i (quan trá»ng nháº¥t).
  - `loss/loss_text`: Loss pháº§n dá»± Ä‘oÃ¡n text (thÆ°á»ng giáº£m nhanh).
  - `loss/total_loss`: Tá»•ng loss.

---

## 6. Tiáº¿p tá»¥c Training (Resume)

Náº¿u quÃ¡ trÃ¬nh training bá»‹ ngáº¯t, cháº¡y láº¡i lá»‡nh cÅ©. Script sáº½ tá»± Ä‘á»™ng tÃ¬m checkpoint gáº§n nháº¥t trong `output_dir` Ä‘á»ƒ tiáº¿p tá»¥c.

---

## 7. Xá»­ lÃ½ lá»—i thÆ°á»ng gáº·p

**Lá»—i: `CUDA out of memory`**
- Giáº£m `--batch_size` (vd: tá»« 8 xuá»‘ng 4 hoáº·c 2).
- Báº­t `--gradient_checkpointing` (máº·c Ä‘á»‹nh Ä‘Ã£ báº­t).
- DÃ¹ng LoRA (`--use_lora`) thay vÃ¬ full finetune.

**Lá»—i: `Loss = NaN`**
- Script Ä‘Ã£ tÃ­ch há»£p `SafeZLoss` vÃ  `Logit Clamping` Ä‘á»ƒ xá»­ lÃ½ viá»‡c nÃ y.
- Náº¿u váº«n bá»‹, thá»­ giáº£m `--lr` xuá»‘ng (vd: 1e-5).
- Kiá»ƒm tra láº¡i dataset xem cÃ³ audio bá»‹ lá»—i (quÃ¡ ngáº¯n < 0.5s hoáº·c im láº·ng hoÃ n toÃ n) khÃ´ng.

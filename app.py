"""
Viterbox - Gradio Web Interface
"""
import torch
import numpy as np
import librosa
from pathlib import Path
import warnings
import random
import gradio as gr

warnings.filterwarnings('ignore')

import tempfile, os

os.environ["GRADIO_TEMP_DIR"] = tempfile.gettempdir() + "/my_gradio_tmp"
os.makedirs(os.environ["GRADIO_TEMP_DIR"], exist_ok=True)
from viterbox import Viterbox
from viterbox.tts import postprocess_audio

# Sample sentences
SAMPLES = {
    "vi": [
        "Xin chÃ o cÃ¡c báº¡n! TÃ´i lÃ  Viterbox, trá»£ lÃ½ giá»ng nÃ³i thÃ´ng minh Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi Ä‘á»™i ngÅ© Dolly VN. Ráº¥t vui Ä‘Æ°á»£c gáº·p cÃ¡c báº¡n hÃ´m nay.",
        "Viá»‡t Nam lÃ  má»™t quá»‘c gia xinh Ä‘áº¹p náº±m á»Ÿ ÄÃ´ng Nam Ã, vá»›i bá» dÃ y lá»‹ch sá»­ hÆ¡n bá»‘n nghÃ¬n nÄƒm vÄƒn hiáº¿n. Tá»« nhá»¯ng ruá»™ng báº­c thang Sapa Ä‘áº¿n nhá»¯ng bÃ£i biá»ƒn xanh ngáº¯t PhÃº Quá»‘c, Ä‘áº¥t nÆ°á»›c hÃ¬nh chá»¯ S luÃ´n khiáº¿n du khÃ¡ch pháº£i say Ä‘áº¯m.",
        "CÃ´ng nghá»‡ trÃ­ tuá»‡ nhÃ¢n táº¡o Ä‘ang phÃ¡t triá»ƒn vá»›i tá»‘c Ä‘á»™ chÃ³ng máº·t. Chá»‰ trong vÃ i nÄƒm gáº§n Ä‘Ã¢y, AI Ä‘Ã£ cÃ³ thá»ƒ viáº¿t vÄƒn, váº½ tranh, vÃ  giá» Ä‘Ã¢y lÃ  tá»•ng há»£p giá»ng nÃ³i tá»± nhiÃªn nhÆ° con ngÆ°á»i.",
        "HÃ  Ná»™i, thá»§ Ä‘Ã´ ngÃ n nÄƒm vÄƒn hiáº¿n cá»§a Viá»‡t Nam, ná»•i tiáº¿ng vá»›i ba mÆ°Æ¡i sÃ¡u phá»‘ phÆ°á»ng vÃ  nhá»¯ng mÃ³n Äƒn Ä‘Æ°á»ng phá»‘ tuyá»‡t vá»i. Phá»Ÿ, bÃºn cháº£, cÃ  phÃª trá»©ng lÃ  nhá»¯ng Ä‘áº·c sáº£n mÃ  báº¡n khÃ´ng thá»ƒ bá» qua khi Ä‘áº¿n Ä‘Ã¢y.",
        "ChÃ o má»«ng báº¡n Ä‘áº¿n vá»›i tháº¿ giá»›i cá»§a Text-to-Speech! Vá»›i Viterbox, báº¡n cÃ³ thá»ƒ biáº¿n báº¥t ká»³ vÄƒn báº£n nÃ o thÃ nh giá»ng nÃ³i tá»± nhiÃªn, mÆ°á»£t mÃ  chá»‰ trong vÃ i giÃ¢y.",
    ],
    "en": [
        "Hello everyone! I am Viterbox, an intelligent voice assistant developed by the Dolly VN team. It's a pleasure to meet you today.",
        "Artificial intelligence technology is advancing at a breathtaking pace. In just a few years, AI has learned to write, create art, and now synthesize natural human-like speech.",
        "Vietnam is a beautiful country located in Southeast Asia, with over four thousand years of rich cultural heritage. From the terraced rice fields of Sapa to the pristine beaches of Phu Quoc, this S-shaped nation never fails to captivate visitors.",
        "Welcome to the world of Text-to-Speech technology! With Viterbox, you can transform any written text into natural, smooth voice output in just seconds.",
        "The future of human-computer interaction is voice. As we move towards a more connected world, voice assistants will become an integral part of our daily lives.",
    ],
}

# Load model
print("=" * 50)
print("ğŸš€ Loading Viterbox...")
print("=" * 50)

if torch.cuda.is_available():
    DEVICE = "cuda"
elif torch.backends.mps.is_available():
    DEVICE = "mps"
else:
    DEVICE = "cpu"
print(f"Device: {DEVICE}")

MODEL = Viterbox.from_pretrained(DEVICE)
print("âœ… Model loaded!")
print("=" * 50)


def list_voices() -> list[str]:
    """List available voice files"""
    wav_dir = Path("wavs")
    if wav_dir.exists():
        return sorted([str(f) for f in wav_dir.glob("*.wav")])
    return []


def get_random_voice() -> str:
    """Get a random voice file from wavs folder"""
    voices = list_voices()
    if voices:
        return random.choice(voices)
    return None


def generate_speech(
    text: str,
    language: str,
    reference_audio,
    exaggeration: float,
    cfg_weight: float,
    temperature: float,
    sentence_pause: float,
):
    """Generate speech from text"""
    if not text.strip():
        return None, "âŒ Please enter some text"
    
    # Get reference audio path - use random voice if not provided
    ref_path = reference_audio if reference_audio else get_random_voice()
    
    if ref_path is None:
        return None, "âŒ No reference audio! Add .wav files to wavs/ folder"
    
    try:
        # Generate
        wav = MODEL.generate(
            text=text.strip(),
            language=language,
            audio_prompt=ref_path,
            exaggeration=exaggeration,
            cfg_weight=cfg_weight,
            temperature=temperature,
            sentence_pause_ms=int(sentence_pause * 1000),  # Convert seconds to ms
        )
        
        # Convert to numpy
        audio_np = wav[0].cpu().numpy()
        
        # Full postprocessing: highpass filter + trim + fade-out
        audio_np = postprocess_audio(audio_np, MODEL.sr)
        
        duration = len(audio_np) / MODEL.sr
        status = f"âœ… Generated! | {duration:.2f}s | {language.upper()}"
        
        return (MODEL.sr, audio_np), status
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return None, f"âŒ Error: {str(e)}"


# CSS
CSS = """
body, .gradio-container { background: #0f172a !important; }
.gradio-container { max-width: 100% !important; padding: 1rem 2rem !important; }
.status-badge { 
    display: inline-flex; align-items: center; padding: 4px 12px;
    border-radius: 999px; font-size: 0.8rem; font-weight: 500;
    background: #4f46e5; color: #fff;
}
#main-row { gap: 1rem !important; }
#main-row > div { flex: 1 !important; min-width: 0 !important; }
.card { 
    background: #1e293b !important; border-radius: 0.75rem;
    border: 1px solid #334155 !important; padding: 1rem 1.25rem; height: 100%;
}
.section-title { 
    font-size: 0.85rem; font-weight: 600; color: #e5e7eb;
    margin-bottom: 0.5rem; display: flex; align-items: center; gap: 0.4rem;
}
.generate-btn { 
    background: #4f46e5 !important; border-radius: 0.5rem !important;
    font-size: 1rem !important; padding: 10px 24px !important; margin-top: 0.75rem !important;
}
.output-card { 
    background: #1e293b !important; border-radius: 0.75rem;
    border: 1px solid #334155 !important; padding: 1rem 1.25rem; margin-top: 0.75rem;
}
"""

# Build UI
with gr.Blocks(
    title="ğŸ™ï¸ Viterbox TTS",
    theme=gr.themes.Soft(primary_hue="indigo", secondary_hue="slate", neutral_hue="slate"),
    css=CSS
) as demo:
    
    gr.HTML("""
        <div style="text-align: center; margin-bottom: 0.5rem;">
            <h1 style="margin: 0; font-size: 2rem;">ğŸ™ï¸ Viterbox TTS</h1>
            <p style="color: #6b7280; margin-top: 0.5rem;">Vietnamese & English Text-to-Speech</p>
        </div>
    """)
    
    gr.HTML('<div style="text-align: center; margin-bottom: 1rem;"><span class="status-badge">ğŸ¯ Fine-tuned Model</span></div>')
    
    with gr.Row(equal_height=True, elem_id="main-row"):
        # Left - Text Input
        with gr.Column(scale=1, elem_classes=["card"]):
            gr.HTML('<div class="section-title">ğŸ“ Text Input</div>')
            
            language = gr.Radio(
                choices=[("ğŸ‡»ğŸ‡³ Tiáº¿ng Viá»‡t", "vi"), ("ğŸ‡ºğŸ‡¸ English", "en")],
                value="vi", label="Language"
            )
            
            text_input = gr.Textbox(
                label="Text to Synthesize",
                placeholder="Nháº­p vÄƒn báº£n cáº§n Ä‘á»c...",
                lines=5
            )
            
            with gr.Row():
                sample_btn = gr.Button("ğŸ² Random", variant="secondary", size="sm")
                clear_btn = gr.Button("ğŸ—‘ï¸ Clear", variant="secondary", size="sm")
        
        # Right - Voice & Settings
        with gr.Column(scale=1, elem_classes=["card"]):
            gr.HTML('<div class="section-title">ğŸ¤ Reference Voice</div>')
            
            wav_files = list_voices()
            if wav_files:
                ref_dropdown = gr.Dropdown(
                    choices=[(Path(f).stem, f) for f in wav_files],
                    label="Select Voice",
                    value=wav_files[0] if wav_files else None,
                )
            else:
                ref_dropdown = gr.Dropdown(choices=[], label="No voices in wavs/")
            
            ref_audio = gr.Audio(label="Or Upload/Record", type="filepath", sources=["upload", "microphone"])
            
            gr.HTML('<div class="section-title" style="margin-top: 0.75rem;">âš™ï¸ Settings</div>')
            
            exaggeration = gr.Slider(0.0, 2.0, 0.5, step=0.05, label="Exaggeration", info="Expression")
            
            with gr.Row():
                cfg_weight = gr.Slider(0.0, 1.0, 0.5, step=0.05, label="CFG Weight", info="Voice adherence")
                temperature = gr.Slider(0.1, 1.0, 0.8, step=0.05, label="Temperature", info="Variation")
            
            sentence_pause = gr.Slider(0.0, 2.0, 0.5, step=0.1, label="Sentence Pause (s)", info="Pause between sentences")
    
    # Generate button
    generate_btn = gr.Button("ğŸ”Š Generate Speech", variant="primary", size="lg", elem_classes=["generate-btn"])
    
    # Output
    with gr.Column(elem_classes=["output-card"]):
        gr.HTML('<div class="section-title">ğŸ”ˆ Output</div>')
        with gr.Row():
            output_audio = gr.Audio(label="Generated Speech", type="numpy", scale=2)
            status_text = gr.Textbox(label="Status", lines=2, scale=1)
    
    # Handlers
    sample_btn.click(
        fn=lambda lang: random.choice(SAMPLES.get(lang, SAMPLES["vi"])),
        inputs=[language],
        outputs=[text_input]
    )
    clear_btn.click(fn=lambda: "", outputs=[text_input])
    ref_dropdown.change(fn=lambda x: x, inputs=[ref_dropdown], outputs=[ref_audio])
    
    generate_btn.click(
        fn=generate_speech,
        inputs=[text_input, language, ref_audio, exaggeration, cfg_weight, temperature, sentence_pause],
        outputs=[output_audio, status_text]
    )


if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False)
